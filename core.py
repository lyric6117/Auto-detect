"""æ ¸å¿ƒç­›é€‰é€»è¾‘ï¼ˆä¸¥æ ¼éµå¾ªDINOv3 demoï¼‰"""

import os
import sys
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from pathlib import Path
from PIL import Image
from tqdm import tqdm
from sklearn.decomposition import PCA
from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors
from sklearn.ensemble import IsolationForest
from sklearn.cluster import MiniBatchKMeans
from sklearn.neighbors import KernelDensity
import matplotlib.pyplot as plt
import pandas as pd
import cv2
import datetime
from typing import List, Dict, Tuple
from torchvision import transforms

class AnomalyScreener:
    """å¼‚å¸¸æ ·æœ¬ç­›é€‰å™¨ï¼ˆä¾›äººå·¥æ ‡æ³¨ä½¿ç”¨ï¼‰"""

    def __init__(self, config):
        self.config = config
        self.device = torch.device(config.DEVICE)

        print("="*70)
        print("ğŸ¯ å¼‚å¸¸æ ·æœ¬ç­›é€‰ç³»ç»Ÿï¼ˆä¾›äººå·¥æ ‡æ³¨ï¼‰")
        print("="*70)
        print(f"è®¾å¤‡: {self.device}")

        # âœ… åˆå§‹åŒ–æ ‡å‡†é¢„å¤„ç†ç®¡é“ï¼ˆéµå¾ªdemoï¼‰
        self.transform = self._get_dinov3_transform()

        # åŠ è½½DINOv3æ¨¡å‹
        self.model = self._load_dinov3()

        # æ•°æ®å­˜å‚¨
        self.all_features = None
        self.all_paths = None
        self.pca = None
        self.scaler = None

    def _get_dinov3_transform(self):
        """âœ… DINOv3å®˜æ–¹æ¨èçš„é¢„å¤„ç†ç®¡é“ï¼ˆå®Œå…¨éµå¾ªdemoï¼‰"""
        return transforms.Compose([
            transforms.Resize(
                (self.config.IMAGE_SIZE, self.config.IMAGE_SIZE),
                interpolation=transforms.InterpolationMode.BICUBIC
            ),
            transforms.ToTensor(),  # è‡ªåŠ¨è½¬ä¸ºfloat32å¹¶å½’ä¸€åŒ–åˆ°[0,1]
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            ),
        ])

    def _load_dinov3(self):
        """åŠ è½½DINOv3æ¨¡å‹ï¼ˆä¸¥æ ¼éµå¾ªdemoï¼‰"""
        print(f"\nğŸ“¥ åŠ è½½DINOv3æ¨¡å‹: {self.config.MODEL_NAME}")

        # æ·»åŠ DINOv3è·¯å¾„
        repo_root = self.config.DINOV3_REPO_ROOT
        sys.path.insert(0, repo_root)

        # âœ… æ­£ç¡®çš„å¯¼å…¥æ–¹å¼
        import dinov3.distributed as distributed
        from dinov3.configs import setup_config, DinoV3SetupArgs, setup_job
        from dinov3.models import build_model_for_eval

        # é…ç½®è·¯å¾„
        config_path = os.path.join(
            repo_root, "dinov3", "configs", "train", f"{self.config.MODEL_NAME}.yaml"
        )

        if not os.path.exists(config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")

        # åˆå§‹åŒ–åˆ†å¸ƒå¼ç¯å¢ƒ
        output_dir = "./outputs/dinov3_tmp"
        os.makedirs(output_dir, exist_ok=True)

        setup_job(
            output_dir=output_dir,
            distributed_enabled=False,
            seed=42,
            distributed_timeout=datetime.timedelta(minutes=30)
        )

        # åˆ›å»ºé…ç½®
        setup_args = DinoV3SetupArgs(
            config_file=config_path,
            pretrained_weights=self.config.DINOV3_WEIGHT_PATH,
            output_dir=output_dir,
            opts=[]
        )

        # åŠ è½½é…ç½®å’Œæ¨¡å‹
        cfg = setup_config(setup_args, strict_cfg=False)
        model = build_model_for_eval(
            config=cfg,
            pretrained_weights=self.config.DINOV3_WEIGHT_PATH
        )

        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval().to(self.device)
        for p in model.parameters():
            p.requires_grad = False

        print(f"âœ… DINOv3æ¨¡å‹åŠ è½½å®Œæˆ")
        print(f"   è¿›ç¨‹æ•°: {distributed.get_world_size()}")

        return model

    def _get_image_paths(self, directory):
        """è·å–æ‰€æœ‰å›¾åƒè·¯å¾„"""
        extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.JPG', '.JPEG', '.PNG', '.BMP')
        paths = []
        directory = Path(directory)
        for ext in extensions:
            paths.extend(directory.glob(f"*{ext}"))
            paths.extend(directory.rglob(f"*{ext}"))  # åŒ…å«å­ç›®å½•
        # å»é‡å¹¶æ’åº
        paths = sorted(list(set(paths)))
        return [str(p) for p in paths]

    @torch.no_grad()
    def extract_all_features(self, image_dir=None):
        """âœ… æå–æ‰€æœ‰å›¾åƒç‰¹å¾ï¼ˆå®Œå…¨éµå¾ªdemoçš„æ‰¹é‡å¤„ç†æ–¹å¼ï¼‰"""
        if image_dir is None:
            image_dir = self.config.IMAGE_DIR

        print("\n" + "="*70)
        print("ğŸ” æå–å›¾åƒç‰¹å¾")
        print("="*70)

        # 1. è·å–æ‰€æœ‰å›¾åƒ
        image_paths = self._get_image_paths(image_dir)
        print(f"ğŸ“‚ æ‰¾åˆ°å›¾åƒ: {len(image_paths)} å¼ ")

        if len(image_paths) == 0:
            raise ValueError(f"æœªæ‰¾åˆ°å›¾åƒ: {image_dir}")

        # 2. æ‰¹é‡æå–ç‰¹å¾ï¼ˆéµå¾ªdemoï¼‰
        features_list = []
        valid_paths = []

        for i in tqdm(range(0, len(image_paths), self.config.BATCH_SIZE),
                     desc="æå–ç‰¹å¾"):
            batch_paths = image_paths[i:i + self.config.BATCH_SIZE]
            batch_images = []
            batch_valid_paths = []

            # âœ… æ‰¹é‡åŠ è½½å›¾åƒï¼ˆdemoæ–¹å¼ï¼‰
            for path in batch_paths:
                try:
                    img = Image.open(path).convert('RGB')
                    img_tensor = self.transform(img)  # ä½¿ç”¨transformsç®¡é“
                    batch_images.append(img_tensor)
                    batch_valid_paths.append(path)
                except Exception as e:
                    print(f"âš ï¸  è·³è¿‡ {path}: {e}")
                    continue

            if len(batch_images) == 0:
                continue

            # âœ… æ‰¹é‡æ¨ç†ï¼ˆdemoæ–¹å¼ï¼‰
            batch_tensor = torch.stack(batch_images).to(self.device)

            # âœ… ä½¿ç”¨forward_featuresæå–ï¼ˆdemoæ–¹å¼ï¼‰
            with torch.no_grad():
                feats_dict = self.model.forward_features(batch_tensor)

                # âœ… æå–patch tokensç‰¹å¾ï¼ˆdemoæ¨èï¼‰
                if 'x_norm_patchtokens' in feats_dict:
                    feats = feats_dict['x_norm_patchtokens']
                elif 'x_prenorm' in feats_dict:
                    feats = feats_dict['x_prenorm']
                else:
                    # å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°è¯•å–ç¬¬ä¸€ä¸ªtensor
                    feats = list(feats_dict.values())[0]

                # âœ… L2å½’ä¸€åŒ–ï¼ˆdemoæ¨èï¼‰
                if self.config.NORMALIZE_FEATURES:
                    feats = F.normalize(feats, dim=-1)

                # âœ… Flatten patchç»´åº¦ï¼ˆdemoæ–¹å¼ï¼‰
                # feats shape: (batch, n_patches, dim)
                if feats.dim() == 3:
                    batch_size, n_patches, dim = feats.shape
                    feats = feats.reshape(batch_size * n_patches, dim)

                features_list.append(feats.cpu().numpy())

            valid_paths.extend(batch_valid_paths)

        # 3. åˆå¹¶ç‰¹å¾
        features = np.vstack(features_list)
        self.all_paths = valid_paths

        print(f"âœ… ç‰¹å¾æå–å®Œæˆ: {features.shape}")

        # 4. å¯é€‰çš„PCAé™ç»´
        if self.config.USE_PCA:
            # è®¡ç®—æ¯å¼ å›¾çš„patchæ•°é‡
            n_images = len(valid_paths)
            n_total_patches = features.shape[0]
            patches_per_image = n_total_patches // n_images

            print(f"ğŸ“Š ç‰¹å¾ç»Ÿè®¡: {n_images} å¼ å›¾åƒ, æ¯å¼  {patches_per_image} ä¸ªpatches")

            # å…ˆå¯¹patchç‰¹å¾åšå¹³å‡ï¼Œå¾—åˆ°å›¾åƒçº§ç‰¹å¾
            features_img = features.reshape(n_images, patches_per_image, -1).mean(axis=1)

            pca_dim = min(self.config.PCA_DIM, features_img.shape[1], len(features_img) - 1)
            print(f"ğŸ“‰ PCAé™ç»´: {features_img.shape[1]} â†’ {pca_dim}")

            self.pca = PCA(n_components=pca_dim, random_state=42)
            features_img = self.pca.fit_transform(features_img)

            var_ratio = self.pca.explained_variance_ratio_.sum()
            print(f"   è§£é‡Šæ–¹å·®æ¯”: {var_ratio:.2%}")

            self.all_features = features_img.astype(np.float32)
        else:
            # ä¸é™ç»´ï¼šç›´æ¥å¯¹patchåšå¹³å‡å¾—åˆ°å›¾åƒçº§ç‰¹å¾
            n_images = len(valid_paths)
            n_total_patches = features.shape[0]
            patches_per_image = n_total_patches // n_images

            features_img = features.reshape(n_images, patches_per_image, -1).mean(axis=1)
            self.all_features = features_img.astype(np.float32)

        print(f"ğŸ“Š æœ€ç»ˆç‰¹å¾: {self.all_features.shape}")

        return self.all_features, self.all_paths

    def compute_anomaly_scores(self):
        """è®¡ç®—å¼‚å¸¸åˆ†æ•°ï¼ˆå¤šç§æ–¹æ³•èåˆï¼‰"""
        print("\n" + "="*70)
        print("ğŸ’¯ è®¡ç®—å¼‚å¸¸åˆ†æ•°")
        print("="*70)

        scores_dict = {}
        methods = self.config.METHODS

        # 1. KNNè·ç¦»
        if 'knn' in methods:
            print("ğŸ“Š KNNè·ç¦»...")
            scores_dict['knn'] = self._compute_knn_score()

        # 2. LOF
        if 'lof' in methods:
            print("ğŸ“Š å±€éƒ¨ç¦»ç¾¤å› å­(LOF)...")
            scores_dict['lof'] = self._compute_lof_score()

        # 3. Isolation Forest
        if 'isolation' in methods:
            print("ğŸ“Š å­¤ç«‹æ£®æ—...")
            scores_dict['isolation'] = self._compute_isolation_score()

        # 4. æ ¸å¯†åº¦ä¼°è®¡
        if 'density' in methods:
            print("ğŸ“Š æ ¸å¯†åº¦ä¼°è®¡...")
            scores_dict['density'] = self._compute_density_score()

        # 5. èåˆåˆ†æ•°
        print("ğŸ”„ èåˆå¼‚å¸¸åˆ†æ•°...")
        ensemble_score = self._ensemble_scores(scores_dict)
        scores_dict['ensemble'] = ensemble_score

        # ç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ åˆ†æ•°ç»Ÿè®¡:")
        for name, scores in scores_dict.items():
            print(f"   {name:12s}: mean={scores.mean():.4f}, "
                  f"std={scores.std():.4f}, "
                  f"max={scores.max():.4f}")

        return scores_dict

    def _compute_knn_score(self):
        """KNNè·ç¦»åˆ†æ•°"""
        k = min(self.config.KNN_K, len(self.all_features) - 1)
        nbrs = NearestNeighbors(n_neighbors=k+1, metric='euclidean', n_jobs=-1)
        nbrs.fit(self.all_features)
        distances, _ = nbrs.kneighbors(self.all_features)

        # æ’é™¤è‡ªèº«ï¼Œå–å‡å€¼
        knn_dist = distances[:, 1:].mean(axis=1)

        return knn_dist

    def _compute_lof_score(self):
        """LOFåˆ†æ•°"""
        n_neighbors = min(self.config.LOF_NEIGHBORS, len(self.all_features) - 1)

        lof = LocalOutlierFactor(
            n_neighbors=n_neighbors,
            contamination='auto',
            n_jobs=-1
        )

        lof.fit(self.all_features)
        # è´Ÿçš„ç¦»ç¾¤å› å­ï¼Œè½¬ä¸ºæ­£å€¼ï¼ˆè¶Šå¤§è¶Šå¼‚å¸¸ï¼‰
        lof_scores = -lof.negative_outlier_factor_

        return lof_scores

    def _compute_isolation_score(self):
        """å­¤ç«‹æ£®æ—åˆ†æ•°"""
        iso = IsolationForest(
            contamination=self.config.ISO_CONTAMINATION,
            random_state=42,
            n_jobs=-1
        )

        iso.fit(self.all_features)
        # å¼‚å¸¸åˆ†æ•°ï¼ˆè¶Šè´Ÿè¶Šå¼‚å¸¸ï¼Œè½¬ä¸ºæ­£å€¼ï¼‰
        iso_scores = -iso.score_samples(self.all_features)

        return iso_scores

    def _compute_density_score(self):
        """æ ¸å¯†åº¦ä¼°è®¡åˆ†æ•°"""
        kde = KernelDensity(
            bandwidth=self.config.DENSITY_BANDWIDTH,
            kernel='gaussian'
        )
        kde.fit(self.all_features)

        # å¯¹æ•°ä¼¼ç„¶ï¼ˆè¶Šä½è¶Šå¼‚å¸¸ï¼Œå–è´Ÿï¼‰
        log_density = kde.score_samples(self.all_features)
        density_scores = -log_density

        return density_scores

    def _ensemble_scores(self, scores_dict):
        """èåˆå¤šä¸ªåˆ†æ•°"""
        if len(scores_dict) == 0:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å¼‚å¸¸åˆ†æ•°")

        # å½’ä¸€åŒ–æ¯ä¸ªåˆ†æ•°åˆ°[0, 1]
        normalized = []

        for name, scores in scores_dict.items():
            # Min-Maxå½’ä¸€åŒ–
            min_val = scores.min()
            max_val = scores.max()

            if max_val > min_val:
                norm_scores = (scores - min_val) / (max_val - min_val)
            else:
                norm_scores = np.zeros_like(scores)

            normalized.append(norm_scores)

        # ç®€å•å¹³å‡èåˆ
        ensemble = np.mean(normalized, axis=0)

        return ensemble

    def select_samples_for_annotation(self, scores):
        """é€‰æ‹©æ ·æœ¬ä¾›äººå·¥æ ‡æ³¨"""
        print("\n" + "="*70)
        print("ğŸ¯ ç­›é€‰å¼‚å¸¸æ ·æœ¬")
        print("="*70)

        # ç¡®å®šç­›é€‰æ•°é‡
        if self.config.USE_TOP_K:
            n_select = min(self.config.TOP_K, len(scores))
        else:
            n_select = int(len(scores) * self.config.TOP_PERCENT)

        print(f"ğŸ“Œ ç­›é€‰ç­–ç•¥: {'Top-K' if self.config.USE_TOP_K else 'ç™¾åˆ†æ¯”'}")
        print(f"ğŸ“Œ ç­›é€‰æ•°é‡: {n_select} / {len(scores)} ({n_select/len(scores)*100:.1f}%)")

        if self.config.USE_DIVERSITY_SAMPLING:
            # å¤šæ ·æ€§é‡‡æ ·ï¼šå…ˆèšç±»ï¼Œå†ä»æ¯ç±»é€‰å¼‚å¸¸æ ·æœ¬
            selected_indices = self._diversity_sampling(scores, n_select)
        else:
            # ç®€å•Top-K
            selected_indices = np.argsort(scores)[-n_select:][::-1]

        print(f"âœ… ç­›é€‰å®Œæˆ: {len(selected_indices)} ä¸ªæ ·æœ¬")

        return selected_indices

    def _diversity_sampling(self, scores, n_select):
        """å¤šæ ·æ€§é‡‡æ ·ï¼ˆé¿å…åªé€‰åŒä¸€ç±»å¼‚å¸¸ï¼‰"""
        print("ğŸ¨ ä½¿ç”¨å¤šæ ·æ€§é‡‡æ ·...")

        # 1. èšç±»
        n_clusters = min(self.config.N_CLUSTERS, len(self.all_features) // 10)
        n_clusters = max(2, n_clusters)  # è‡³å°‘2ä¸ªç±»

        print(f"   èšç±»æ•°: {n_clusters}")

        kmeans = MiniBatchKMeans(
            n_clusters=n_clusters,
            random_state=42,
            batch_size=min(1024, len(self.all_features)),
            n_init=3
        )
        cluster_labels = kmeans.fit_predict(self.all_features)

        # 2. æ¯ä¸ªç±»é€‰å¼‚å¸¸åˆ†æ•°æœ€é«˜çš„æ ·æœ¬
        samples_per_cluster = max(1, n_select // n_clusters)

        selected_indices = []

        for cluster_id in range(n_clusters):
            cluster_mask = cluster_labels == cluster_id
            cluster_indices = np.where(cluster_mask)[0]

            if len(cluster_indices) == 0:
                continue

            # åœ¨è¯¥ç±»ä¸­é€‰å¼‚å¸¸åˆ†æ•°æœ€é«˜çš„
            cluster_scores = scores[cluster_indices]
            n_select_cluster = min(samples_per_cluster, len(cluster_indices))
            top_in_cluster = np.argsort(cluster_scores)[-n_select_cluster:][::-1]

            selected_indices.extend(cluster_indices[top_in_cluster])

        # 3. å¦‚æœä¸å¤Ÿï¼Œè¡¥å……å…¨å±€Top
        if len(selected_indices) < n_select:
            remaining = n_select - len(selected_indices)
            all_top = np.argsort(scores)[::-1]

            for idx in all_top:
                if idx not in selected_indices:
                    selected_indices.append(idx)
                    if len(selected_indices) >= n_select:
                        break

        # 4. æŒ‰åˆ†æ•°æ’åº
        selected_indices = np.array(selected_indices[:n_select])
        selected_scores = scores[selected_indices]
        sort_order = np.argsort(selected_scores)[::-1]
        selected_indices = selected_indices[sort_order]

        print(f"   é‡‡æ ·åˆ†å¸ƒ: æ¯ç±»çº¦{samples_per_cluster}ä¸ª")

        return selected_indices

    def save_results(self, scores_dict, selected_indices):
        """ä¿å­˜ç­›é€‰ç»“æœ"""
        output_dir = Path(self.config.OUTPUT_DIR)
        output_dir.mkdir(exist_ok=True)

        print("\n" + "="*70)
        print("ğŸ’¾ ä¿å­˜ç»“æœ")
        print("="*70)

        # 1. å®Œæ•´ç»“æœCSVï¼ˆæ‰€æœ‰å›¾åƒï¼‰
        df_all = pd.DataFrame({
            'image_path': self.all_paths,
            'image_name': [Path(p).name for p in self.all_paths],
            'ensemble_score': scores_dict['ensemble'],
        })

        # æ·»åŠ å„æŒ‡æ ‡åˆ†æ•°
        for name, scores in scores_dict.items():
            if name != 'ensemble':
                df_all[f'{name}_score'] = scores

        # æ·»åŠ æ˜¯å¦è¢«é€‰ä¸­æ ‡è®°
        df_all['selected_for_annotation'] = 0
        df_all.loc[selected_indices, 'selected_for_annotation'] = 1

        # æŒ‰åˆ†æ•°æ’åº
        df_all = df_all.sort_values('ensemble_score', ascending=False)

        csv_all = output_dir / 'all_images_with_scores.csv'
        df_all.to_csv(csv_all, index=False, encoding='utf-8-sig')
        print(f"ğŸ“„ å®Œæ•´ç»“æœ: {csv_all}")

        # 2. ç­›é€‰å‡ºçš„å¼‚å¸¸æ ·æœ¬CSVï¼ˆä¾›æ ‡æ³¨ï¼‰
        df_selected = df_all[df_all['selected_for_annotation'] == 1].copy()
        df_selected['annotation_label'] = ''  # ç©ºåˆ—ä¾›äººå·¥å¡«å†™
        df_selected['annotation_notes'] = ''  # å¤‡æ³¨åˆ—

        csv_selected = output_dir / 'samples_for_annotation.csv'
        df_selected.to_csv(csv_selected, index=False, encoding='utf-8-sig')
        print(f"ğŸ“„ å¾…æ ‡æ³¨æ ·æœ¬: {csv_selected} ({len(df_selected)} ä¸ª)")

        # 3. ç»Ÿè®¡æ‘˜è¦
        summary = {
            'æ€»å›¾åƒæ•°': len(self.all_paths),
            'ç­›é€‰æ•°é‡': len(selected_indices),
            'ç­›é€‰æ¯”ä¾‹': f"{len(selected_indices)/len(self.all_paths)*100:.2f}%",
            'åˆ†æ•°å‡å€¼': f"{scores_dict['ensemble'].mean():.4f}",
            'åˆ†æ•°æ ‡å‡†å·®': f"{scores_dict['ensemble'].std():.4f}",
            'é€‰ä¸­æ ·æœ¬æœ€ä½åˆ†': f"{scores_dict['ensemble'][selected_indices].min():.4f}",
            'é€‰ä¸­æ ·æœ¬æœ€é«˜åˆ†': f"{scores_dict['ensemble'][selected_indices].max():.4f}",
        }

        summary_file = output_dir / 'summary.txt'
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("="*70 + "\n")
            f.write("å¼‚å¸¸æ ·æœ¬ç­›é€‰æ‘˜è¦\n")
            f.write("="*70 + "\n\n")
            for k, v in summary.items():
                f.write(f"{k:20s}: {v}\n")

        print(f"ğŸ“„ æ‘˜è¦: {summary_file}")

        # 4. å¯è§†åŒ–
        if self.config.SAVE_VISUALIZATIONS:
            self._visualize_results(scores_dict, selected_indices, output_dir)

        print(f"\nğŸ“ æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")

        return csv_selected

    def _visualize_results(self, scores_dict, selected_indices, output_dir):
        """å¯è§†åŒ–ç»“æœ"""
        print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–...")

        scores = scores_dict['ensemble']

        # 1. åˆ†æ•°åˆ†å¸ƒå›¾
        plt.figure(figsize=(12, 6))

        plt.subplot(1, 2, 1)
        plt.hist(scores, bins=100, alpha=0.7, color='skyblue', edgecolor='black')

        # æ ‡è®°é€‰ä¸­æ ·æœ¬çš„åˆ†æ•°èŒƒå›´
        selected_scores = scores[selected_indices]
        threshold = selected_scores.min()
        plt.axvline(threshold, color='red', linestyle='--', linewidth=2,
                   label=f'Selection Threshold: {threshold:.3f}')

        plt.xlabel('Anomaly Score', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        plt.title('Score Distribution (All Images)', fontsize=14)
        plt.legend()
        plt.grid(True, alpha=0.3)

        # 2. é€‰ä¸­æ ·æœ¬çš„åˆ†æ•°åˆ†å¸ƒ
        plt.subplot(1, 2, 2)
        plt.hist(selected_scores, bins=50, alpha=0.7, color='salmon', edgecolor='black')
        plt.xlabel('Anomaly Score', fontsize=12)
        plt.ylabel('Count', fontsize=12)
        plt.title('Score Distribution (Selected for Annotation)', fontsize=14)
        plt.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(output_dir / 'score_distribution.png', dpi=200, bbox_inches='tight')
        plt.close()
        print("   âœ“ åˆ†æ•°åˆ†å¸ƒå›¾")

        # 3. Topå¼‚å¸¸æ ·æœ¬å¯è§†åŒ–
        viz_k = min(self.config.VIZ_TOP_K, len(selected_indices))
        top_indices = selected_indices[:viz_k]

        n_cols = self.config.GRID_COLS
        n_rows = (viz_k + n_cols - 1) // n_cols

        fig, axes = plt.subplots(n_rows, n_cols, figsize=(4*n_cols, 4*n_rows))
        if n_rows == 1 and n_cols == 1:
            axes = np.array([axes])
        elif n_rows == 1 or n_cols == 1:
            axes = axes.flatten()
        else:
            axes = axes.flatten()

        for i, idx in enumerate(top_indices):
            if i >= len(axes):
                break

            img_path = self.all_paths[idx]
            score = scores[idx]

            try:
                img = cv2.imread(img_path)
                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            except:
                img = np.zeros((224, 224, 3), dtype=np.uint8)

            axes[i].imshow(img)
            axes[i].set_title(f'Rank {i+1}\nScore: {score:.4f}\n{Path(img_path).name}',
                            fontsize=9)
            axes[i].axis('off')

        # éšè—å¤šä½™å­å›¾
        for i in range(len(top_indices), len(axes)):
            axes[i].axis('off')

        plt.tight_layout()
        plt.savefig(output_dir / f'top_{viz_k}_anomalies.png', dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   âœ“ Top-{viz_k} å¼‚å¸¸æ ·æœ¬å›¾")
