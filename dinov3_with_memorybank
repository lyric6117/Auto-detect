import os
import sys

import torch
import torch.nn.functional as F
from torchvision import transforms
from PIL import Image
import faiss
import numpy as np
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm
import warnings
import datetime  # å¯¼å…¥æ ‡å‡†åº“çš„datetimeæ¨¡å—
import dinov3.distributed as distributed
from dinov3.configs import setup_config, DinoV3SetupArgs, setup_job  # ä¿®æ­£é…ç½®å¯¼å…¥ï¼ˆåŽŸæ‹¼å†™é”™è¯¯+æ­£ç¡®å‡½æ•°ï¼‰
from dinov3.models import build_model_for_eval  # æ”¹ç”¨è¯„ä¼°æ¨¡å¼æž„å»ºå‡½æ•°


warnings.filterwarnings("ignore")


# ======== æ ¸å¿ƒé…ç½®ï¼ˆéµå¾ªDINOv3å®˜æ–¹æŽ¨èï¼‰ ========
class Config:
    # æ¨¡åž‹é…ç½®
    MODEL_NAME = "dinov3_vitl16_lvd1689m_distilled"
    PATCH_SIZE = 16  # ä¸Žæ¨¡åž‹åŒ¹é…ï¼ˆ14ä¸ºé»˜è®¤ï¼Œvitg14æ”¯æŒ28ï¼‰
    IMG_SIZE = 576  #

    # å¼‚å¸¸æ£€æµ‹å‚æ•°ï¼ˆå®˜æ–¹ç»éªŒå€¼ï¼‰
    K_NEIGHBORS = 5  # è¿‘é‚»æ•°ï¼ˆ5-10æœ€ä½³ï¼‰
    PERCENTILE = 95  # å›¾åƒçº§åˆ†æ•°è®¡ç®—åˆ†ä½æ•°
    FEATURE_LAYER = "x_norm_patchtokens"  # æŽ¨èä½¿ç”¨å½’ä¸€åŒ–åŽçš„patchç‰¹å¾
    NORM_TYPE = "l2"  # ç‰¹å¾å½’ä¸€åŒ–æ–¹å¼ï¼ˆå®˜æ–¹æŽ¨èl2ï¼‰

    # æ€§èƒ½é…ç½®
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    BATCH_SIZE = 8  # æ‰¹é‡ç‰¹å¾æå–ï¼ˆGPUå……è¶³å¯å¢žå¤§ï¼‰
    FAISS_INDEX_TYPE = "FlatL2"  # å®˜æ–¹æŽ¨èï¼šå°è§„æ¨¡ç”¨FlatL2ï¼Œå¤§è§„æ¨¡ç”¨IVF
    GPU_INDEX = torch.cuda.is_available()  # FAISSæ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ


# ======== Step 1: DINOv3æ¨¡åž‹åŠ è½½ï¼ˆä¸¥æ ¼éµå¾ªå®˜æ–¹ç”¨æ³•ï¼‰ ========

def load_dinov3_model(
        weight_path=r"D:\ly\dinov3-main\dinov3_vitl16_pretrain_lvd1689m-8aa4cbdd.pth",
        model_name=Config.MODEL_NAME,
        use_pretrain=True
):
    repo_root = r"D:\ly\dinov3-main"
    sys.path.append(repo_root)

    # æž„å»ºé…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆè·¨å¹³å°å…¼å®¹ï¼‰
    config_path = os.path.join(
        repo_root, "dinov3", "configs", "train", f"{model_name}.yaml"
    )

    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config_path):
        raise FileNotFoundError(
            f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}\n"
            f"è¯·ç¡®è®¤model_nameæ˜¯å¦ä¸ºä»¥ä¸‹ä¹‹ä¸€ï¼š\n"
            f"- dinov3_vitl16_lvd1689m_distilled\n"
            f"- vitl_im1k_lin834"
        )

    # åˆå§‹åŒ–åˆ†å¸ƒå¼çŽ¯å¢ƒï¼ˆä¿®æ­£Timedeltaçš„ä½¿ç”¨ï¼‰
    output_dir = "./outputs"
    setup_job(
        output_dir=output_dir,
        distributed_enabled=False,
        seed=42,
        distributed_timeout=datetime.timedelta(minutes=30)
    )

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)

    # åˆ›å»ºé…ç½®å‚æ•°
    setup_args = DinoV3SetupArgs(
        config_file=config_path,
        pretrained_weights=weight_path,
        output_dir=output_dir,
        opts=[]
    )

    # åŠ è½½é…ç½®
    cfg = setup_config(setup_args, strict_cfg=False)

    # æž„å»ºæ¨¡åž‹
    model = build_model_for_eval(
        config=cfg,
        pretrained_weights=weight_path
    )

    # è®¾ç½®è®¾å¤‡å’Œè¯„ä¼°æ¨¡å¼
    model.eval().to(Config.DEVICE)
    for p in model.parameters():
        p.requires_grad = False

    print(
        f"âœ… æˆåŠŸåŠ è½½ DINOv3 æ¨¡åž‹: {model_name}\n"
        f"è®¾å¤‡: {Config.DEVICE}\n"
        f"åˆ†å¸ƒå¼è¿›ç¨‹æ•°: {distributed.get_world_size()}"
    )
    return model

# ======== Step 2: é¢„å¤„ç†ç®¡é“ï¼ˆä¸¥æ ¼éµå¾ªDINOv3å®˜æ–¹è§„èŒƒï¼‰ ========
def get_dinov3_transform(img_size=Config.IMG_SIZE):
    """
    èŽ·å–DINOv3å®˜æ–¹æŽ¨èçš„å›¾åƒé¢„å¤„ç†ç®¡é“
    å‚è€ƒï¼šhttps://github.com/facebookresearch/dinov3#preprocessing
    """
    return transforms.Compose([
        transforms.Resize((img_size, img_size), interpolation=transforms.InterpolationMode.BICUBIC),
        transforms.ToTensor(),
        # å®˜æ–¹å½’ä¸€åŒ–å‚æ•°ï¼ˆä¸ŽDINOv2ä¿æŒä¸€è‡´ï¼Œä½†å¼ºåˆ¶ä½¿ç”¨ï¼‰
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
    ])


transform = get_dinov3_transform()


# ======== Step 3: ç‰¹å¾æå–ï¼ˆæ”¯æŒæ‰¹é‡å¤„ç†å’Œåˆ†å±‚ç‰¹å¾ï¼‰ ========
def extract_single_feature(img_path, model, transform):
    """å•å¼ å›¾åƒç‰¹å¾æå–ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰"""
    img = Image.open(img_path).convert("RGB")
    x = transform(img).unsqueeze(0).to(Config.DEVICE)
    with torch.no_grad():
        feats_dict = model.forward_features(x)
        # èŽ·å–æŒ‡å®šå±‚ç‰¹å¾ï¼ˆå®˜æ–¹æŽ¨èx_norm_patchtokensï¼‰
        feats = feats_dict[Config.FEATURE_LAYER]
        # ç‰¹å¾å½’ä¸€åŒ–ï¼ˆå®˜æ–¹å¼ºåˆ¶è¦æ±‚ï¼Œæå‡æ£€ç´¢æ•ˆæžœï¼‰
        if Config.NORM_TYPE == "l2":
            feats = F.normalize(feats, dim=-1)
    return feats.squeeze(0).cpu().numpy()


def extract_batch_features(img_paths, model, transform, batch_size=Config.BATCH_SIZE):
    """æ‰¹é‡ç‰¹å¾æå–ï¼ˆå®˜æ–¹æŽ¨èï¼Œæå‡æ•ˆçŽ‡ï¼‰"""
    all_feats = []
    for i in tqdm(range(0, len(img_paths), batch_size), desc="ðŸ“¥ æ‰¹é‡æå–ç‰¹å¾"):
        batch_paths = img_paths[i:i + batch_size]
        # æ‰¹é‡åŠ è½½å›¾åƒ
        imgs = [Image.open(path).convert("RGB") for path in batch_paths]
        x = torch.stack([transform(img) for img in imgs]).to(Config.DEVICE)
        # æ‰¹é‡æå–ç‰¹å¾
        with torch.no_grad():
            feats_dict = model.forward_features(x)
            feats = feats_dict[Config.FEATURE_LAYER]
            if Config.NORM_TYPE == "l2":
                feats = F.normalize(feats, dim=-1)
        all_feats.append(feats.cpu().numpy())
    return np.concatenate(all_feats, axis=0)


def get_patch_grid_size(img_size=Config.IMG_SIZE, patch_size=Config.PATCH_SIZE):
    """è®¡ç®—patchç½‘æ ¼å°ºå¯¸ï¼ˆç¡®ä¿æ•´é™¤ï¼Œå®˜æ–¹è¦æ±‚ï¼‰"""
    assert img_size % patch_size == 0, f"âŒ å›¾åƒå°ºå¯¸{img_size}å¿…é¡»èƒ½è¢«patchå°ºå¯¸{patch_size}æ•´é™¤"
    return (img_size // patch_size, img_size // patch_size)


# ======== Step 4: ä¼˜åŒ–çš„Memory Bankï¼ˆFAISSå®˜æ–¹æœ€ä½³å®žè·µï¼‰ ========
class MemoryBank:
    def __init__(self):
        self.index = None
        self.feats = None
        self.dim = None
        self.grid_h, self.grid_w = get_patch_grid_size()

    def build(self, normal_paths, model, transform):
        """æž„å»ºå†…å­˜é“¶è¡Œï¼ˆæ”¯æŒæ‰¹é‡å¤„ç†å’ŒGPUåŠ é€Ÿï¼‰"""
        print(f"ðŸ”¨ å¼€å§‹æž„å»ºMemory Bankï¼ˆæ­£å¸¸æ ·æœ¬æ•°ï¼š{len(normal_paths)}ï¼‰")

        # æ‰¹é‡æå–æ­£å¸¸æ ·æœ¬ç‰¹å¾
        self.feats = extract_batch_features(normal_paths, model, transform)
        print(f"ðŸ“Š æå–ç‰¹å¾ç»Ÿè®¡ï¼šæ€»æ•°={len(self.feats)}, shape={self.feats.shape}")

        # âœ… flatten patch ç‰¹å¾
        if self.feats.ndim == 3:
            n_img, n_patch, dim = self.feats.shape
            self.feats = self.feats.reshape(n_img * n_patch, dim)
            self.dim = dim
        else:
            self.dim = self.feats.shape[1]

        print(f"âœ… Flatten åŽç‰¹å¾ï¼š{self.feats.shape}")

        # æž„å»ºFAISSç´¢å¼•
        self._build_faiss_index()
        print(f"âœ… Memory Bankæž„å»ºå®Œæˆï¼ˆç´¢å¼•ç±»åž‹ï¼š{Config.FAISS_INDEX_TYPE}ï¼‰")

    def _build_faiss_index(self):
        """æž„å»ºFAISSç´¢å¼•ï¼ˆæ”¯æŒGPUåŠ é€Ÿï¼‰"""
        if Config.FAISS_INDEX_TYPE == "FlatL2":
            self.index = faiss.IndexFlatL2(self.dim)
        elif Config.FAISS_INDEX_TYPE == "IVF":
            # å¤§è§„æ¨¡æ•°æ®æŽ¨èï¼šIVFç´¢å¼•ï¼ˆéœ€è¦è®­ç»ƒï¼‰
            nlist = min(100, len(self.feats) // 10)
            self.index = faiss.IndexIVFFlat(
                faiss.IndexFlatL2(self.dim), self.dim, nlist, faiss.METRIC_L2
            )
            self.index.train(self.feats.astype(np.float32))
        else:
            raise ValueError(f"âŒ ä¸æ”¯æŒçš„ç´¢å¼•ç±»åž‹ï¼š{Config.FAISS_INDEX_TYPE}")

        # GPUåŠ é€Ÿï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        if Config.GPU_INDEX:
            res = faiss.StandardGpuResources()
            self.index = faiss.index_cpu_to_gpu(res, 0, self.index)

        self.index.add(self.feats.astype(np.float32))

    def search(self, query_feats, k=Config.K_NEIGHBORS):
        """æœç´¢æœ€è¿‘é‚»ï¼ˆè¿”å›žè·ç¦»å’Œç´¢å¼•ï¼‰"""
        assert self.index is not None, "âŒ Memory Bankæœªæž„å»º"
        query_feats = query_feats.astype(np.float32)
        distances, indices = self.index.search(query_feats, k)
        return distances, indices


# ======== Step 5: å¼‚å¸¸æ£€æµ‹å™¨ï¼ˆç»“åˆDINOv3ç‰¹å¾ç‰¹æ€§ä¼˜åŒ–ï¼‰ ========
class AnomalyDetector:
    def __init__(self, memory_bank, model, transform):
        self.memory_bank = memory_bank
        self.model = model
        self.transform = transform
        self.k = Config.K_NEIGHBORS
        self.percentile = Config.PERCENTILE
        self.grid_h, self.grid_w = get_patch_grid_size()

    def predict(self, img_path, return_heatmap=True):
        """é¢„æµ‹å¼‚å¸¸åˆ†æ•°ï¼ˆä¼˜åŒ–patchåˆ†æ•°è®¡ç®—ï¼‰"""
        # æå–æŸ¥è¯¢ç‰¹å¾
        feats = extract_single_feature(img_path, self.model, self.transform)

        # æœç´¢æœ€è¿‘é‚»
        distances, _ = self.memory_bank.search(feats, self.k)

        # ä¼˜åŒ–ï¼šä½¿ç”¨ä¸­ä½æ•°+å‡å€¼ç»„åˆï¼ˆå®˜æ–¹æŽ¨èï¼Œé²æ£’æ€§æ›´å¼ºï¼‰
        patch_scores = (distances.mean(axis=1) + np.median(distances, axis=1)) / 2

        # å›¾åƒçº§åˆ†æ•°ï¼šä½¿ç”¨95åˆ†ä½æ•°ï¼ˆå®˜æ–¹ç»éªŒå€¼ï¼‰
        img_score = np.percentile(patch_scores, self.percentile)

        if return_heatmap:
            heatmap = patch_scores.reshape(self.grid_h, self.grid_w)
            return img_score, heatmap, patch_scores
        return img_score

    def visualize(self, img_path, save_path="anomaly_visualization.png"):
        """å¯è§†åŒ–ä¼˜åŒ–ï¼ˆå®˜æ–¹é£Žæ ¼çƒ­åŠ›å›¾ï¼‰"""
        img_score, heatmap, _ = self.predict(img_path)

        # çƒ­åŠ›å›¾åŽå¤„ç†ï¼ˆå®˜æ–¹æŽ¨èï¼šå¹³æ»‘+å½’ä¸€åŒ–ï¼‰
        heatmap_norm = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
        # åŒçº¿æ€§æ’å€¼åˆ°åŽŸå›¾å°ºå¯¸ï¼ˆä¿æŒç»†èŠ‚ï¼‰
        heatmap_resized = cv2.resize(
            heatmap_norm, (Config.IMG_SIZE, Config.IMG_SIZE),
            interpolation=cv2.INTER_LINEAR
        )
        # é«˜æ–¯å¹³æ»‘ï¼ˆæ ¸å¤§å°ä¸ºpatch_sizeçš„æ•´æ•°å€ï¼‰
        smooth_kernel = Config.PATCH_SIZE * 2 + 1
        heatmap_smooth = cv2.GaussianBlur(heatmap_resized, (smooth_kernel, smooth_kernel), 0)

        # åŠ è½½å¹¶è°ƒæ•´åŽŸå›¾
        img = Image.open(img_path).convert("RGB").resize((Config.IMG_SIZE, Config.IMG_SIZE))
        img = np.array(img)

        # å®˜æ–¹é£Žæ ¼å¯è§†åŒ–
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))

        # åŽŸå›¾
        axes[0].imshow(img)
        axes[0].set_title("Original Image", fontsize=14, fontweight="bold")
        axes[0].axis("off")

        # çƒ­åŠ›å›¾
        im = axes[1].imshow(heatmap_smooth, cmap="jet")
        axes[1].set_title("Anomaly Heatmap", fontsize=14, fontweight="bold")
        axes[1].axis("off")
        # æ·»åŠ é¢œè‰²æ¡ï¼ˆå®˜æ–¹æŽ¨èï¼‰
        cbar = plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)
        cbar.set_label("Anomaly Score", fontsize=12)

        # å åŠ å›¾
        axes[2].imshow(img)
        axes[2].imshow(heatmap_smooth, cmap="jet", alpha=0.5)
        axes[2].set_title(f"Anomaly Detection\nScore: {img_score:.4f}", fontsize=14, fontweight="bold")
        axes[2].axis("off")

        plt.tight_layout()
        plt.savefig(save_path, dpi=200, bbox_inches="tight", facecolor="white")
        print(f"ðŸ“¸ å¯è§†åŒ–ç»“æžœå·²ä¿å­˜è‡³ï¼š{save_path}")


# ======== Step 6: å·¥å…·å‡½æ•°ï¼ˆæ•°æ®æ ¡éªŒ+ç»“æžœåˆ†æžï¼‰ ========
def validate_data_paths(normal_dir, test_dir):
    """æ ¡éªŒæ•°æ®è·¯å¾„ï¼ˆå®˜æ–¹æŽ¨èçš„è¾“å…¥æ£€æŸ¥ï¼‰"""
    normal_dir = Path(normal_dir)
    test_dir = Path(test_dir)

    # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    assert normal_dir.exists(), f"âŒ æ­£å¸¸æ ·æœ¬æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼š{normal_dir}"
    assert test_dir.exists(), f"âŒ æµ‹è¯•æ ·æœ¬æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼š{test_dir}"

    # èŽ·å–æ”¯æŒçš„å›¾åƒæ ¼å¼ï¼ˆå®˜æ–¹æŽ¨èï¼špng/jpg/jpegï¼‰
    img_extensions = (".png", ".jpg", ".jpeg")
    normal_paths = [p for p in normal_dir.glob("*") if p.suffix.lower() in img_extensions]
    test_paths = [p for p in test_dir.glob("*") if p.suffix.lower() in img_extensions]

    # æ£€æŸ¥æ ·æœ¬æ•°é‡
    assert len(normal_paths) > 0, f"âŒ æ­£å¸¸æ ·æœ¬æ–‡ä»¶å¤¹ä¸ºç©ºï¼š{normal_dir}"
    assert len(test_paths) > 0, f"âŒ æµ‹è¯•æ ·æœ¬æ–‡ä»¶å¤¹ä¸ºç©ºï¼š{test_dir}"

    print(f"ðŸ“ æ•°æ®ç»Ÿè®¡ï¼šæ­£å¸¸æ ·æœ¬={len(normal_paths)}, æµ‹è¯•æ ·æœ¬={len(test_paths)}")
    return normal_paths, test_paths


def calculate_threshold(results, method="otsu"):
    """è®¡ç®—å¼‚å¸¸é˜ˆå€¼ï¼ˆå®˜æ–¹æŽ¨èOtsuè‡ªåŠ¨é˜ˆå€¼ï¼‰"""
    scores = np.array([s for _, s in results], dtype=np.float32)
    if method == "otsu":
        # Otsué˜ˆå€¼æ³•ï¼ˆè‡ªåŠ¨åŒºåˆ†æ­£å¸¸/å¼‚å¸¸ï¼‰
        scores_norm = (scores - np.min(scores)) / (np.max(scores) - np.min(scores)) * 255
        scores_norm = scores_norm.astype(np.uint8)
        # æ³¨æ„ï¼šcv2.threshold çš„è¿”å›žæ˜¯ (é˜ˆå€¼, äºŒå€¼åŒ–å›¾åƒ)
        otsu_val, _ = cv2.threshold(scores_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        # åå½’ä¸€åŒ–å›žåŽŸå§‹åˆ†æ•°åŒºé—´
        threshold = otsu_val / 255 * (np.max(scores) - np.min(scores)) + np.min(scores)
    else:
        # ç»éªŒé˜ˆå€¼ï¼ˆ95åˆ†ä½æ•°ï¼‰
        threshold = np.percentile(scores, 95)

    # é˜²æ­¢thresholdæ˜¯æ•°ç»„
    if isinstance(threshold, np.ndarray):
        threshold = float(threshold.ravel()[0])

    print(f"ðŸ“ è®¡ç®—å¼‚å¸¸é˜ˆå€¼ï¼š{threshold:.4f}ï¼ˆæ–¹æ³•ï¼š{method}ï¼‰")
    return threshold



# ======== Step 7: å®Œæ•´æµç¨‹ï¼ˆå®˜æ–¹æŽ¨èçš„æ‰§è¡Œé¡ºåºï¼‰ ========
if __name__ == "__main__":
    # 1. é…ç½®æ•°æ®è·¯å¾„ï¼ˆè¯·æ ¹æ®å®žé™…æƒ…å†µä¿®æ”¹ï¼‰
    normal_dir = r"C:\Users\Administrator\Desktop\f-AnoGAN\RD4AD-main\mvtec\zhawa_guzhang\train\good"
    test_dir = r"C:\Users\Administrator\Desktop\f-AnoGAN\RD4AD-main\mvtec\zhawa_guzhang\test\zhawa,cuanchu"

    # 2. æ•°æ®æ ¡éªŒ
    normal_paths, test_paths = validate_data_paths(normal_dir, test_dir)

    # 3. åŠ è½½DINOv3æ¨¡åž‹
    model = load_dinov3_model(model_name=Config.MODEL_NAME)

    # 4. æž„å»ºMemory Bank
    memory_bank = MemoryBank()
    memory_bank.build(normal_paths, model, transform)

    # 5. åˆ›å»ºå¼‚å¸¸æ£€æµ‹å™¨
    detector = AnomalyDetector(memory_bank, model, transform)

    # 6. æ‰¹é‡æ£€æµ‹æµ‹è¯•æ ·æœ¬
    print("\nðŸ” å¼€å§‹æ‰¹é‡å¼‚å¸¸æ£€æµ‹...")
    results = []
    for test_path in tqdm(test_paths, desc="æ£€æµ‹è¿›åº¦"):
        img_score = detector.predict(test_path, return_heatmap=False)
        results.append((test_path.name, img_score))

    # 7. ç»“æžœåˆ†æžä¸ŽæŽ’åº
    results.sort(key=lambda x: x[1], reverse=True)
    threshold = calculate_threshold(results, method="otsu")

    # 8. è¾“å‡ºå¼‚å¸¸æ£€æµ‹ç»“æžœ
    print("\nðŸš¨ å¼‚å¸¸æ£€æµ‹ç»“æžœï¼ˆæŒ‰å¼‚å¸¸åˆ†æ•°é™åºï¼‰ï¼š")
    for idx, (name, score) in enumerate(results[:10], 1):
        status = "å¼‚å¸¸" if score > threshold else "æ­£å¸¸"
        print(f"  Top{idx:2d}: {name:<20} åˆ†æ•°ï¼š{score:.4f} çŠ¶æ€ï¼š{status}")

    # 9. å¯è§†åŒ–Top1å¼‚å¸¸æ ·æœ¬
    if results:
        top_anomaly_name = results[0][0]
        top_anomaly_path = Path(test_dir) / top_anomaly_name
        print(f"\nðŸ“Š å¯è§†åŒ–Top1å¼‚å¸¸æ ·æœ¬ï¼š{top_anomaly_name}")
        detector.visualize(str(top_anomaly_path), save_path="top_anomaly_visualization.png")

    print("\nðŸŽ‰ å¼‚å¸¸æ£€æµ‹æµç¨‹å®Œæˆï¼")
